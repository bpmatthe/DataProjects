{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7-2.\n",
    "Consider the MNIST dataset we worked on in the last module. Only consider the train \n",
    "set. Create and train 5 different networks with different number of hidden layers from\n",
    "1 through 5. Every hidden layer should have about 30 neurons. Report the accuracy on the \n",
    "train set and the training time taken to reach it. Please comment on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-f29388702db7>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/brentmatthews/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/brentmatthews/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/brentmatthews/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/brentmatthews/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/brentmatthews/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "accucracy is  0.9094\n",
      "354 µs ± 9.07 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# training data\n",
    "#prepare dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# define computational graph\n",
    "# Create the model\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.layers.dense(x,10)\n",
    "\n",
    "#initializer\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Define loss and optimizer\n",
    "y_ = tf.placeholder(tf.int64, [None,10])\n",
    "cross_entropy = tf.losses.softmax_cross_entropy(onehot_labels=y_, logits=y)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n",
    "\n",
    "loss_log = []\n",
    "\n",
    "#run the graph as session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) # reset values to wrong\n",
    "    # training loop\n",
    "    for _ in range(1000):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "        loss,_ = sess.run([cross_entropy,train_step], feed_dict={x: batch_xs, y_: batch_ys})\n",
    "        loss_log.append(loss)\n",
    "\n",
    "    # Test trained model\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1),tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    accuracy_result = sess.run(accuracy, feed_dict={x: mnist.test.images,y_: mnist.test.labels})\n",
    "    print(\"accuracy is \",accuracy_result)\n",
    "    %timeit sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "accucracy is  0.9169\n",
      "727 µs ± 128 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# training data\n",
    "#prepare dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# define computational graph\n",
    "# Create the model\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "h = tf.layers.dense(x,50)\n",
    "y = tf.layers.dense(h,10)\n",
    "\n",
    "#initializer\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Define loss and optimizer\n",
    "y_ = tf.placeholder(tf.int64, [None,10])\n",
    "cross_entropy = tf.losses.softmax_cross_entropy(onehot_labels=y_, logits=y)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n",
    "\n",
    "loss_log = []\n",
    "\n",
    "#run the graph as session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) # reset values to wrong\n",
    "    # training loop\n",
    "    for _ in range(1000):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "        loss,_ = sess.run([cross_entropy,train_step], feed_dict={x: batch_xs, y_: batch_ys})\n",
    "        loss_log.append(loss)\n",
    "\n",
    "    # Test trained model\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1),tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    accuracy_result = sess.run(accuracy, feed_dict={x: mnist.test.images,y_: mnist.test.labels})\n",
    "    print(\"accuracy is \",accuracy_result)\n",
    "    %timeit sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "accucracy is  0.915\n",
      "905 µs ± 80.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# training data\n",
    "#prepare dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# define computational graph\n",
    "# Create the model\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "h = tf.layers.dense(x,30)\n",
    "r = tf.layers.dense(h,30)\n",
    "y = tf.layers.dense(r,10)\n",
    "\n",
    "#initializer\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Define loss and optimizer\n",
    "y_ = tf.placeholder(tf.int64, [None,10])\n",
    "cross_entropy = tf.losses.softmax_cross_entropy(onehot_labels=y_, logits=y)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n",
    "\n",
    "loss_log = []\n",
    "\n",
    "#run the graph as session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) # reset values to wrong\n",
    "    # training loop\n",
    "    for _ in range(1000):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "        loss,_ = sess.run([cross_entropy,train_step], feed_dict={x: batch_xs, y_: batch_ys})\n",
    "        loss_log.append(loss)\n",
    "\n",
    "    # Test trained model\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1),tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    accuracy_result = sess.run(accuracy, feed_dict={x: mnist.test.images,y_: mnist.test.labels})\n",
    "    print(\"accuracy is \",accuracy_result)\n",
    "    %timeit sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "accucracy is  0.915\n",
      "1.26 ms ± 94.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# training data\n",
    "#prepare dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# define computational graph\n",
    "# Create the model\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "h = tf.layers.dense(x,30)\n",
    "j = tf.layers.dense(h,30)\n",
    "r = tf.layers.dense(j,30)\n",
    "y = tf.layers.dense(r,10)\n",
    "\n",
    "#initializer\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Define loss and optimizer\n",
    "y_ = tf.placeholder(tf.int64, [None,10])\n",
    "cross_entropy = tf.losses.softmax_cross_entropy(onehot_labels=y_, logits=y)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n",
    "\n",
    "loss_log = []\n",
    "\n",
    "#run the graph as session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) # reset values to wrong\n",
    "    # training loop\n",
    "    for _ in range(1000):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "        loss,_ = sess.run([cross_entropy,train_step], feed_dict={x: batch_xs, y_: batch_ys})\n",
    "        loss_log.append(loss)\n",
    "\n",
    "    # Test trained model\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1),tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    accuracy_result = sess.run(accuracy, feed_dict={x: mnist.test.images,y_: mnist.test.labels})\n",
    "    print(\"accuracy is \",accuracy_result)\n",
    "    %timeit sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "accucracy is  0.9148\n",
      "1.34 ms ± 195 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# training data\n",
    "#prepare dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "from tensorflow.python.client import timeline\n",
    "\n",
    "# define computational graph\n",
    "# Create the model\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "h = tf.layers.dense(x,30)\n",
    "j = tf.layers.dense(h,30)\n",
    "k = tf.layers.dense(j,30)\n",
    "r = tf.layers.dense(k,30)\n",
    "y = tf.layers.dense(r,10)\n",
    "\n",
    "#initializer\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Define loss and optimizer\n",
    "y_ = tf.placeholder(tf.int64, [None,10])\n",
    "cross_entropy = tf.losses.softmax_cross_entropy(onehot_labels=y_, logits=y)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n",
    "\n",
    "loss_log = []\n",
    "\n",
    "#run the graph as session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) # reset values to wrong\n",
    "    # training loop\n",
    "    for _ in range(1000):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "        loss,_ = sess.run([cross_entropy,train_step], feed_dict={x: batch_xs, y_: batch_ys})\n",
    "        loss_log.append(loss)\n",
    "\n",
    "    # Test trained model\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1),tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    accuracy_result = sess.run(accuracy, feed_dict={x: mnist.test.images,y_: mnist.test.labels})\n",
    "    print(\"accuracy is \",accuracy_result)\n",
    "    %timeit sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "accucracy is  0.902\n",
      "1.52 ms ± 190 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# training data\n",
    "#prepare dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "from tensorflow.python.client import timeline\n",
    "\n",
    "# define computational graph\n",
    "# Create the model\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "h = tf.layers.dense(x,30)\n",
    "j = tf.layers.dense(h,30)\n",
    "k = tf.layers.dense(j,30)\n",
    "l = tf.layers.dense(k,30)\n",
    "r = tf.layers.dense(l,30)\n",
    "y = tf.layers.dense(r,10)\n",
    "\n",
    "#initializer\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Define loss and optimizer\n",
    "y_ = tf.placeholder(tf.int64, [None,10])\n",
    "cross_entropy = tf.losses.softmax_cross_entropy(onehot_labels=y_, logits=y)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n",
    "\n",
    "loss_log = []\n",
    "\n",
    "#run the graph as session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) # reset values to wrong\n",
    "    # training loop\n",
    "    for _ in range(1000):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "        loss,_ = sess.run([cross_entropy,train_step], feed_dict={x: batch_xs, y_: batch_ys})\n",
    "        loss_log.append(loss)\n",
    "\n",
    "    # Test trained model\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1),tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    accuracy_result = sess.run(accuracy, feed_dict={x: mnist.test.images,y_: mnist.test.labels})\n",
    "    print(\"accuracy is \",accuracy_result)\n",
    "    %timeit sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments\n",
    "The accuracy of the network peaked with the 2-layer network, accuracy was 0.9169. As I went to the next level, a 3-layer, the accuracy dropped to 0.915. With all the networks, the more layers there were the longer it took to run the computations. That means if we were doing a really large data set, we might want to stop this one at 2 or 3 layers as not to waste time and money."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
